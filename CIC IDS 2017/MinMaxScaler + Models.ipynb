{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "# Importing the required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_train_rusb.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_train_rusb.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"X_test_rusb.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_test_rusb.pickle\",\"rb\")\n",
    "y_test = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "boost = xgb.XGBClassifier(max_depth=9,\n",
    "                          subsample=0.9,\n",
    "                          objective='multi:softmax',\n",
    "                          num_class = 3,\n",
    "                          min_child_weight=2,\n",
    "                          colsample_bytree=0.7,\n",
    "                          n_estimators=100,\n",
    "                          learning_rate=0.08,\n",
    "                          n_jobs = -1)\n",
    "boost.fit(X_train,y_train)\n",
    "boost_pred = boost.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961909608722034"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_score(y_test,boost_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127217    565]\n",
      " [   408 127255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    127782\n",
      "           1       1.00      1.00      1.00    127663\n",
      "\n",
      "    accuracy                           1.00    255445\n",
      "   macro avg       1.00      1.00      1.00    255445\n",
      "weighted avg       1.00      1.00      1.00    255445\n",
      "\n",
      "0.9961909608722034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,boost_pred))  \n",
    "print(classification_report(y_test,boost_pred))  \n",
    "print(accuracy_score(y_test, boost_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(random_state=10)\n",
    "tree_model.fit(X_train,y_train)\n",
    "y_pred = tree_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Decision Tree: 0.8316506488676623\n",
      "Depth of the Original Tree :38\n",
      "No of leaves in the Original Tree :1102\n",
      "[[127436    346]\n",
      " [ 42658  85005]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for Decision Tree:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Depth of the Original Tree :\" + str(tree_model.get_depth()))\n",
    "print(\"No of leaves in the Original Tree :\" + str(tree_model.get_n_leaves()))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearchCV to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=10),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20, 30],\n",
       "                         'splitter': ['best', 'random']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=10)\n",
    "params = {'splitter': ['best', 'random'], 'max_depth': [10,20,30], 'criterion': ['gini', 'entropy']}\n",
    "grid_search_cv = GridSearchCV(tree_model, params, cv= 5)\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988440313595575"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = tree.DecisionTreeClassifier(random_state=10, criterion='entropy', max_depth=20, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model.fit(X_train,y_train)\n",
    "y_pred = tree_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Decision Tree: 0.9913719195913014\n",
      "Depth of the Original Tree :20\n",
      "No of leaves in the Original Tree :515\n",
      "[[126752   1030]\n",
      " [  1174 126489]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for Decision Tree:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Depth of the Original Tree :\" + str(tree_model.get_depth()))\n",
    "print(\"No of leaves in the Original Tree :\" + str(tree_model.get_n_leaves()))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    127782\n",
      "           1       0.99      0.99      0.99    127663\n",
      "\n",
      "    accuracy                           0.99    255445\n",
      "   macro avg       0.99      0.99      0.99    255445\n",
      "weighted avg       0.99      0.99      0.99    255445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning : Experiment with optimizing precision and recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyper-parameters for Precision\n",
      "Best parameters set\n",
      "{'criterion': 'entropy', 'max_depth': 20, 'splitter': 'best'}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    127782\n",
      "           1       0.99      0.99      0.99    127663\n",
      "\n",
      "    accuracy                           0.99    255445\n",
      "   macro avg       0.99      0.99      0.99    255445\n",
      "weighted avg       0.99      0.99      0.99    255445\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.994 (+/-0.001) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.963 (+/-0.015) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.999 (+/-0.000) for {'criterion': 'gini', 'max_depth': 20, 'splitter': 'best'}\n",
      "0.995 (+/-0.004) for {'criterion': 'gini', 'max_depth': 20, 'splitter': 'random'}\n",
      "0.999 (+/-0.000) for {'criterion': 'gini', 'max_depth': 25, 'splitter': 'best'}\n",
      "0.997 (+/-0.001) for {'criterion': 'gini', 'max_depth': 25, 'splitter': 'random'}\n",
      "0.998 (+/-0.000) for {'criterion': 'gini', 'max_depth': 30, 'splitter': 'best'}\n",
      "0.998 (+/-0.000) for {'criterion': 'gini', 'max_depth': 30, 'splitter': 'random'}\n",
      "0.997 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.957 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.999 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 20, 'splitter': 'best'}\n",
      "0.993 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 20, 'splitter': 'random'}\n",
      "0.999 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 25, 'splitter': 'best'}\n",
      "0.997 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 25, 'splitter': 'random'}\n",
      "0.999 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 30, 'splitter': 'best'}\n",
      "0.998 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 30, 'splitter': 'random'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = [{'splitter': ['best', 'random'], 'max_depth': [10,20,25,30], 'criterion': ['gini', 'entropy']}]\n",
    "tree_model = DecisionTreeClassifier(random_state=10)\n",
    "print('Tuning hyper-parameters for Precision')\n",
    "grid_search = GridSearchCV(estimator = tree_model,\n",
    "                           param_grid = params,\n",
    "                           scoring='precision_weighted',\n",
    "                           cv = 5,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Best parameters set\")\n",
    "print(grid_search.best_params_)\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988445133410903"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126752   1030]\n",
      " [  1174 126489]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
