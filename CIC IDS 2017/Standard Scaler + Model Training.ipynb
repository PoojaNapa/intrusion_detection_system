{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing essential libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "# import cv2\n",
    "import random \n",
    "import math\n",
    "# import imblearn\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_train_rusb.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_train_rusb.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"X_test_rusb.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_test_rusb.pickle\",\"rb\")\n",
    "y_test = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to model and predict\n",
    "rfc = RandomForestClassifier()\n",
    "y_pred = rfc.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier results for CIC IDS 2017 n\n",
      "Total datapoints: 255445\n",
      "Correct datapoints: 206928\n",
      "Mislabeled datapoints: 48517\n",
      "Percent correct: 81.01%\n"
     ]
    }
   ],
   "source": [
    "total_datapoints = X_test.shape[0]\n",
    "mislabeled_datapoints = (y_test != y_pred).sum()\n",
    "correct_datapoints = total_datapoints-mislabeled_datapoints\n",
    "percent_correct = (correct_datapoints / total_datapoints) * 100\n",
    "\n",
    "print(\"RandomForestClassifier results for CIC IDS 2017 n\")\n",
    "print(\"Total datapoints: %d\\nCorrect datapoints: %d\\nMislabeled datapoints: %d\\nPercent correct: %.2f%%\"\n",
    "      % (total_datapoints, correct_datapoints, mislabeled_datapoints, percent_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127782      0]\n",
      " [ 48517  79146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84    127782\n",
      "           1       1.00      0.62      0.77    127663\n",
      "\n",
      "    accuracy                           0.81    255445\n",
      "   macro avg       0.86      0.81      0.80    255445\n",
      "weighted avg       0.86      0.81      0.80    255445\n",
      "\n",
      "0.8100687036348333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:11:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0.3, reg_lambda=1, scale_pos_weight=1, silent=0,\n",
       "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(silent=0,\n",
    "                     scale_pos_weight=1,\n",
    "                     learning_rate=0.01,\n",
    "                     colsample_bytree=0.6,\n",
    "                     subsample=0.8,\n",
    "                     objective='binary:logistic',\n",
    "                     n_estimators=100,\n",
    "                     reg_alpha=0.3,\n",
    "                     max_depth=3,\n",
    "                     gamma=1)\n",
    "\n",
    "model.fit(X_train,y_train,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9366478106833174\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "boost = xgb.XGBClassifier(max_depth=9,\n",
    "                          subsample=0.9,\n",
    "                          objective='multi:softmax',\n",
    "                          num_class = 3,\n",
    "                          min_child_weight=2,\n",
    "                          colsample_bytree=0.7,\n",
    "                          n_estimators=100,\n",
    "                          learning_rate=0.08,\n",
    "                          n_jobs = -1)\n",
    "boost.fit(X_train,y_train)\n",
    "boost_pred = boost.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130027990369747"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_score(y_test,boost_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127768     14]\n",
      " [ 22209 105454]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    127782\n",
      "           1       1.00      0.83      0.90    127663\n",
      "\n",
      "    accuracy                           0.91    255445\n",
      "   macro avg       0.93      0.91      0.91    255445\n",
      "weighted avg       0.93      0.91      0.91    255445\n",
      "\n",
      "0.9130027990369747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,boost_pred))  \n",
    "print(classification_report(y_test,boost_pred))  \n",
    "print(accuracy_score(y_test, boost_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(n_estimators=5, warm_start=True,random_state=3141)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Bagging classifier is: 0.7892148994891268\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for Bagging classifier is:\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125075   2707]\n",
      " [ 51137  76526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82    127782\n",
      "           1       0.97      0.60      0.74    127663\n",
      "\n",
      "    accuracy                           0.79    255445\n",
      "   macro avg       0.84      0.79      0.78    255445\n",
      "weighted avg       0.84      0.79      0.78    255445\n",
      "\n",
      "0.7892148994891268\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train,y_train.values.ravel())\n",
    "knn_prediction = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for KNN: 0.9847246961185382\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for KNN:\",accuracy_score(y_test,knn_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126170   1612]\n",
      " [  2290 125373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    127782\n",
      "           1       0.99      0.98      0.98    127663\n",
      "\n",
      "    accuracy                           0.98    255445\n",
      "   macro avg       0.98      0.98      0.98    255445\n",
      "weighted avg       0.98      0.98      0.98    255445\n",
      "\n",
      "0.9847246961185382\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,knn_prediction))  \n",
    "print(classification_report(y_test,knn_prediction))  \n",
    "print(accuracy_score(y_test, knn_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
